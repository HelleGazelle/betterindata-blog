[
    {
        "title": "Basics",
        "items": [
            {
                "title": "üóíÔ∏è Git",
                "shortdescription": "You should learn Git because it is a powerful tool for version control, enabling you to track changes to your code and data pipelines over time. By using Git, you can collaborate with others, revert to previous versions of your work, and easily manage conflicts that arise from concurrent edits. Finally, Git is widely used in the industry, so learning it will make you as a Data Engineers more marketable and increase your ability to work effectively on larger projects.",
                "links": [
                    {
                        "text": "Git",
                        "url": "https://git-scm.com/"
                    },
                    {
                        "text": "Git - the simple guide",
                        "url": "https://rogerdudler.github.io/git-guide/"
                    },
                    {
                        "text": "What is version control",
                        "url": "https://about.gitlab.com/topics/version-control/"
                    }
                ]
            },
            {
                "title": "üêç Python Basics",
                "shortdescription": "If you're a Data Engineer, learning Python is essential because it's a versatile programming language that's widely used in data engineering. With Python, you can perform various tasks, such as data processing, pipeline management, and automation. Additionally, Python has a vast ecosystem of libraries and frameworks designed specifically for data engineering, including popular ones like Pandas, NumPy, and Spark.",
                "links": [
                    {
                        "text": "Python Basics",
                        "url": "https://www.w3schools.com/python/python_intro.asp"
                    },
                    {
                        "text": "Python Data Science Handbook [Full eBook]",
                        "url": "https://jakevdp.github.io/PythonDataScienceHandbook/"
                    },
                    {
                        "text": "Book: Python for Data Analysis [Ad]",
                        "url": "https://amzn.to/42bGG7o"
                    }
                ]
            },
            {
                "title": "üö¢ Docker & Container",
                "shortdescription": "If you're a Data Engineer, learning Docker is crucial because it allows you to create reproducible and scalable environments for running your data pipelines and applications. With Docker, you can ensure that your code runs consistently across different machines and environments, reducing the risk of errors and compatibility issues. Furthermore, as Docker is widely used in the industry, acquiring this skill will enhance your employability",
                "links": [
                    {
                        "text": "What is Docker?",
                        "url": "https://aws.amazon.com/docker/"
                    },
                    {
                        "text": "Docker Cheat",
                        "url": "https://jakevdp.github.io/PythonDataScienceHandbook/"
                    }
                ]
            }
        ]
    },
    {
        "title": "Data Stores",
        "items": [
            {
                "title": "üë™ Relational Databases",
                "shortdescription": "An understanding of relational databases is important as a Data Scientist because they are a common storage and management system for structured data used in many organizations. By understanding relational databases and how to interact with them using SQL, Data Scientists can extract, transform, and analyze data efficiently and effectively.",
                "links": [
                    {
                        "text": "What is a relational database?",
                        "url": "https://www.ibm.com/topics/relational-databases"
                    },
                    {
                        "text": "Video: Relational Database concepts",
                        "url": "https://www.youtube.com/watch?v=NvrpuBAMddw"
                    }
                ]
            },
            {
                "title": "üíπ SQL",
                "shortdescription": "As a Data Engineer, knowing SQL is mandatory because it is the standard language for querying and manipulating data in relational databases. With SQL, you can extract, transform, and load data from various sources, perform data analysis, and create reports. By mastering SQL, you can build robust and efficient data pipelines that deliver reliable and meaningful insights to your organization.",
                "links": [
                    {
                        "text": "SQL Tutorial",
                        "url": "https://www.w3schools.com/sql/"
                    },
                    {
                        "text": "SQL Cheat Sheet",
                        "url": "https://www.sqltutorial.org/sql-cheat-sheet/"
                    }
                ]
            },
            {
                "title": "üìÅ Database Modelling",
                "shortdescription": "Database and Warehouse Modelling enables you to design and build efficient and scalable databases that can handle large volumes of data. By understanding database modelling concepts, you can optimize data storage, minimize redundancy, and ensure data integrity. This will help you create robust and reliable data pipelines that can support the needs of your organization.",
                "links": [
                    {
                        "text": "What is a Data Warehouse",
                        "url": "https://www.talend.com/resources/what-is-data-warehouse/"
                    },
                    {
                        "text": "Book: The Data Warehouse Toolkit [Ad]",
                        "url": "https://amzn.to/40d6pur"
                    }
                ]
            }
        ]
    },
    {
        "title": "Big Data Technologies",
        "items": [
            {
                "title": "‚è∞ Workflow Orchestration",
                "shortdescription": "Workflow orchestration in a Data perspective refers to the process of designing, scheduling, and managing the various tasks and dependencies involved in a data pipeline. It involves creating a workflow or a series of interconnected tasks that can be executed automatically in a reliable and scalable manner, allowing Data Engineers to manage complex data pipelines more effectively. The 3 most popular tools are Airflow, Prefect and Dagster",
                "links": [
                    {
                        "text": "Apache Airflow for Workflow Orchestration",
                        "url": "https://airflow.apache.org/"
                    },
                    {
                        "text": "Coordinate data workflows with Prefect",
                        "url": "https://www.prefect.io/"
                    },
                    {
                        "text": "Cloud native pipeline orchestration with dagster",
                        "url": "https://dagster.io/"
                    }
                ]            
            },
            {
                "title": "üí† Spark",
                "shortdescription": "Spark is a popular open-source distributed computing framework that provides a unified platform for large-scale data processing. It offers various modules and APIs for batch processing, real-time stream processing, machine learning, and graph processing, making it a powerful tool for building complex data pipelines that can handle massive volumes of data.",
                "links": [
                    {
                        "text": "What is Apache Spark?",
                        "url": "https://cloud.google.com/learn/what-is-apache-spark"
                    },
                    {
                        "text": "When to (not) use Spark",
                        "url": "https://www.pluralsight.com/guides/when-to-use-apache-spark"
                    },
                    {
                        "text": "Hadoop vs Spark",
                        "url": "https://www.ibm.com/cloud/blog/hadoop-vs-spark"
                    }
                ]
            }
        ]
    },
    {
        "title": "Data Architecture",
        "items": [
            {
                "title": "üíâ Data Integration",
                "shortdescription": "Data integration involves combining data from multiple sources into a unified and coherent data store or warehouse. This process requires designing, building, and maintaining a data pipeline that can extract, transform, and load data while ensuring data accuracy, consistency, and completeness.",
                "links": [
                    {
                        "text": "What is Data Integration?",
                        "url": "https://www.talend.com/resources/what-is-data-integration/"
                    },
                    {
                        "text": "Data Integration Best Practices",
                        "url": "https://hevodata.com/learn/data-integration-best-practices/"
                    }
                ]
            },
            {
                "title": "üß∞ Data Quality",
                "shortdescription": "Understanding data quality is essential because it allows you to identify and address any issues with the data you're working with. Poor data quality can lead to incorrect analyses, which can result in inaccurate insights and decision making. By possessing data quality skills, you can ensure the data you use is accurate, complete, and consistent, which ultimately leads to more reliable and valuable insights.",
                "links": [
                    {
                        "text": "What is Data Quality?",
                        "url": "https://www.heavy.ai/technical-glossary/data-quality"
                    },
                    {
                        "text": "Data Quality Rule Cheat Sheet?",
                        "url": "https://www.collibra.com/us/en/resources/data-quality-rule-cheat-sheet"
                    }
                ]
            },
            {
                "title": "üîë Data Security",
                "shortdescription": "Data security is fundamental because it ensures that the sensitive information stored and processed by your organization is protected from unauthorized access, breaches, and theft. Failure to prioritize data security can result in significant financial and reputational damage, legal liability, and loss of trust from stakeholders.",
                "links": [
                    {
                        "text": "What is Data Security?",
                        "url": "https://www.ibm.com/topics/data-security"
                    },
                    {
                        "text": "Book: Security Engineering [Ad]",
                        "url": "https://amzn.to/3mKtea1"
                    }
                ]
            }
        ]
    },
    {
        "title": "Data Analysis",
        "items": [
            {
                "title": "üî¨ Data Visualization",
                "shortdescription": "Data visualization is important for all data workers because it helps them communicate insights and findings to stakeholders in a clear and accessible way, leading to better decision-making and more effective communication. It also helps identify patterns and relationships in data that might not be apparent when looking at raw data, leading to new insights and discoveries.",
                "links": [
                    {
                        "text": "What is Data Analytics?",
                        "url": "https://aws.amazon.com/de/what-is/data-analytics/"
                    },
                    {
                        "text": "Inspiration for impactful data visuals: 'information is beautiful'",
                        "url": "https://informationisbeautiful.net/"
                    },
                    {
                        "text": "Comparison: Google Looker Studio vs Apache Superset",
                        "url": "https://www.restack.io/docs/lookerstudio-vs-superset"
                    }
                ]
            },
            {
                "title": "üß¨ Machine Learning",
                "shortdescription": "Machine learning is a type of artificial intelligence that uses algorithms to enable computer systems to learn from and make decisions based on data. It involves developing models and algorithms that can analyze and learn from data, and then use that knowledge to make predictions or decisions.",
                "links": [
                    {
                        "text": "What is Machine Learning?",
                        "url": "https://www.ibm.com/topics/machine-learning"
                    },
                    {
                        "text": "List of the different types of machine learning",
                        "url": "https://machinelearningmastery.com/types-of-learning-in-machine-learning/"
                    }
                ]
            }
        ]
    },
    {
        "title": "Data Pipelines & Flows",
        "items": [
            {
                "title": "üå´Ô∏è Data Streaming",
                "shortdescription": "Stream processing is important for data engineers because it allows them to analyze and act on real-time data as it is generated. This is essential for applications that require immediate responses, such as fraud detection, stock trading, or traffic monitoring.",
                "links": [
                    {
                        "text": "What is Stream Processing?",
                        "url": "https://hazelcast.com/glossary/stream-processing/"
                    },
                    {
                        "text": "A list of data streaming frameworks and platforms",
                        "url": "https://github.com/manuzhang/awesome-streaming"
                    }
                ]
            },
            {
                "title": "üåä Batch Processing",
                "shortdescription": "Batch processing is a method of processing data in which a set or batch of data is collected over a period of time, and then processed all at once as a single unit. This method is useful for processing large volumes of data that do not require real-time analysis, such as generating reports or performing complex calculations. Batch processing is typically more efficient than stream processing for large datasets, as it can be scheduled during off-peak hours and can take advantage of parallel processing.",
                "links": [
                    {
                        "text": "What is Batch Processing?",
                        "url": "https://aws.amazon.com/de/what-is/batch-processing/"
                    },
                    {
                        "text": "Comparison: Batch Processing vs Stream Processing",
                        "url": "https://hevodata.com/learn/batch-processing-vs-stream-processing/"
                    }
                ]
            },
            {
                "title": "‚ö° Change data capture",
                "shortdescription": "Change data capture is a method of capturing and processing only the changes made to a database, rather than processing the entire database each time. This allows data engineers to process and analyze data in near-real-time, without having to wait for a full database update. CDC is useful for applications that require up-to-date data, such as monitoring systems or financial transactions, and can help reduce the amount of processing and storage required.",
                "links": [
                    {
                        "text": "What is change data capture?",
                        "url": "https://www.qlik.com/us/change-data-capture/cdc-change-data-capture"
                    }
                ]
            },
            {
                "title": "üåå Data Manipulation",
                "shortdescription": "Data manipulation is the process of transforming and modifying data to meet specific needs or requirements. This can involve a variety of operations, such as filtering, sorting, aggregating, and joining data, as well as creating new columns or variables. Data manipulation is a key skill for data engineers, as it enables them to prepare data for analysis, build data pipelines, and create outputs that are tailored to specific use cases or applications.",
                "links": [
                    {
                        "text": "Data Wrangling with pandas Cheat Sheet",
                        "url": "https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf"
                    },
                    {
                        "text": "Fast Data Manipulation with Excel",
                        "url": "https://skillfine.com/excel-data-analysis-techniques/"
                    }
                ]
            }
        ]
    },
    {
        "title": "Cloud Infrastructure",
        "items": [
            {
                "title": "‚òÅÔ∏è Cloud Computing",
                "shortdescription": "Cloud computing is important for data workers because it allows them to store, process, and analyze large amounts of data more efficiently and cost-effectively than traditional solutions. It also provides access to advanced data analytics tools and services that can help data workers gain insights and make better decisions.",
                "links": [
                    {
                        "text": "What is Cloud Computing?",
                        "url": "https://aws.amazon.com/de/what-is-cloud-computing/"
                    },
                    {
                        "text": "Video: Cloud Computing in 6 Minutes",
                        "url": "https://www.youtube.com/watch?v=M988_fsOSWo"
                    }
                ]
            },
            {
                "title": "‚õÖ AWS, Azure, GCP",
                "shortdescription": "Know at least one hyperscaler cloud service provider. Choose your favorite.",
                "links": [
                    {
                        "text": "What is Google Cloud Platform (GCP)?",
                        "url": "https://acloudguru.com/blog/engineering/what-is-google-cloud-platform-gcp"
                    },
                    {
                        "text": "What is Amazon Web Services (AWS)?",
                        "url": "https://aws.amazon.com/de/what-is-aws/"
                    },
                    {
                        "text": "What is Microsoft Azure?",
                        "url": "https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-azure/"
                    },
                    {
                        "text": "Map of all cloud services in GCP vs Aure vs AWS",
                        "url": "https://cloud.google.com/free/docs/aws-azure-gcp-service-comparison"
                    }
                ]
            },
            {
                "title": "üå®Ô∏è Others",
                "shortdescription": "Beside the major hyperscalers there are also other cloud platforms with different specializations. Have a look at them!",
                "links": [
                    {
                        "text": "What is Digital Ocean?",
                        "url": "https://www.digitalocean.com/"
                    },
                    {
                        "text": "What is Alibaba Cloud?",
                        "url": "https://bluexp.netapp.com/blog/alibaba-cloud-computing-an-introduction"
                    }
                ]
            }
        ]
    }
]
