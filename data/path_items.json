[
    {
        "title": "Basics",
        "items": [
            {
                "title": "üóíÔ∏è Git",
                "shortdescription": "You should learn Git because it is a powerful tool for version control, enabling you to track changes to your code and data pipelines over time. By using Git, you can collaborate with others, revert to previous versions of your work, and easily manage conflicts that arise from concurrent edits. Finally, Git is widely used in the industry, so learning it will make you as a Data Engineers more marketable and increase your ability to work effectively on larger projects.",
                "links": [
                    {
                        "text": "Git",
                        "url": "https://git-scm.com/"
                    },
                    {
                        "text": "Git - the simple guide",
                        "url": "https://rogerdudler.github.io/git-guide/"
                    },
                    {
                        "text": "What is version control",
                        "url": "https://about.gitlab.com/topics/version-control/"
                    }
                ]
            },
            {
                "title": "üêç Python Basics",
                "shortdescription": "If you're a Data Engineer, learning Python is essential because it's a versatile programming language that's widely used in data engineering. With Python, you can perform various tasks, such as data processing, pipeline management, and automation. Additionally, Python has a vast ecosystem of libraries and frameworks designed specifically for data engineering, including popular ones like Pandas, NumPy, and Spark.",
                "links": [
                    {
                        "text": "Python Basics",
                        "url": "https://www.w3schools.com/python/python_intro.asp"
                    },
                    {
                        "text": "Python Data Science Handbook [Full eBook]",
                        "url": "https://jakevdp.github.io/PythonDataScienceHandbook/"
                    },
                    {
                        "text": "Book: Python for Data Analysis [Ad]",
                        "url": "https://amzn.to/42bGG7o"
                    }
                ]
            },
            {
                "title": "üö¢ Docker & Container",
                "shortdescription": "If you're a Data Engineer, learning Docker is crucial because it allows you to create reproducible and scalable environments for running your data pipelines and applications. With Docker, you can ensure that your code runs consistently across different machines and environments, reducing the risk of errors and compatibility issues. Furthermore, as Docker is widely used in the industry, acquiring this skill will enhance your employability",
                "links": [
                    {
                        "text": "What is Docker?",
                        "url": "https://aws.amazon.com/docker/"
                    },
                    {
                        "text": "Docker Cheat",
                        "url": "https://jakevdp.github.io/PythonDataScienceHandbook/"
                    }
                ]
            }
        ]
    },
    {
        "title": "Data Stores",
        "items": [
            {
                "title": "üë™ Relational Databases",
                "shortdescription": "An understanding of relational databases is important as a Data Scientist because they are a common storage and management system for structured data used in many organizations. By understanding relational databases and how to interact with them using SQL, Data Scientists can extract, transform, and analyze data efficiently and effectively.",
                "links": [
                    {
                        "text": "What is a relational database?",
                        "url": "https://www.ibm.com/topics/relational-databases"
                    },
                    {
                        "text": "Video: Relational Database concepts",
                        "url": "https://www.youtube.com/watch?v=NvrpuBAMddw"
                    }
                ]
            },
            {
                "title": "üíπ SQL",
                "shortdescription": "As a Data Engineer, knowing SQL is mandatory because it is the standard language for querying and manipulating data in relational databases. With SQL, you can extract, transform, and load data from various sources, perform data analysis, and create reports. By mastering SQL, you can build robust and efficient data pipelines that deliver reliable and meaningful insights to your organization.",
                "links": [
                    {
                        "text": "SQL Tutorial",
                        "url": "https://www.w3schools.com/sql/"
                    },
                    {
                        "text": "SQL Cheat Sheet",
                        "url": "https://www.sqltutorial.org/sql-cheat-sheet/"
                    }
                ]
            },
            {
                "title": "üìÅ Database Modelling",
                "shortdescription": "Database and Warehouse Modelling enables you to design and build efficient and scalable databases that can handle large volumes of data. By understanding database modelling concepts, you can optimize data storage, minimize redundancy, and ensure data integrity. This will help you create robust and reliable data pipelines that can support the needs of your organization.",
                "links": [
                    {
                        "text": "What is a Data Warehouse",
                        "url": "https://www.talend.com/resources/what-is-data-warehouse/"
                    },
                    {
                        "text": "Book: The Data Warehouse Toolkit [Ad]",
                        "url": "https://amzn.to/40d6pur"
                    }
                ]
            }
        ]
    },
    {
        "title": "Big Data Technologies",
        "items": [
            {
                "title": "‚è∞ Workflow Orchestration",
                "shortdescription": "Workflow orchestration in a Data perspective refers to the process of designing, scheduling, and managing the various tasks and dependencies involved in a data pipeline. It involves creating a workflow or a series of interconnected tasks that can be executed automatically in a reliable and scalable manner, allowing Data Engineers to manage complex data pipelines more effectively. The 3 most popular tools are Airflow, Prefect and Dagster",
                "links": [
                    {
                        "text": "Apache Airflow for Workflow Orchestration",
                        "url": "https://airflow.apache.org/"
                    },
                    {
                        "text": "Coordinate data workflows with Prefect",
                        "url": "https://www.prefect.io/"
                    },
                    {
                        "text": "Cloud native pipeline orchestration with dagster",
                        "url": "https://dagster.io/"
                    }
                ]            
            },
            {
                "title": "üí† Spark",
                "shortdescription": "Spark is a popular open-source distributed computing framework that provides a unified platform for large-scale data processing. It offers various modules and APIs for batch processing, real-time stream processing, machine learning, and graph processing, making it a powerful tool for building complex data pipelines that can handle massive volumes of data.",
                "links": [
                    {
                        "text": "What is Apache Spark?",
                        "url": "https://cloud.google.com/learn/what-is-apache-spark"
                    },
                    {
                        "text": "When to (not) use Spark",
                        "url": "https://www.pluralsight.com/guides/when-to-use-apache-spark"
                    },
                    {
                        "text": "Hadoop vs Spark",
                        "url": "https://www.ibm.com/cloud/blog/hadoop-vs-spark"
                    }
                ]
            }
        ]
    },
    {
        "title": "Data Architecture",
        "items": [
            {
                "title": "üíâ Data Integration",
                "shortdescription": "Data integration involves combining data from multiple sources into a unified and coherent data store or warehouse. This process requires designing, building, and maintaining a data pipeline that can extract, transform, and load data while ensuring data accuracy, consistency, and completeness.",
                "links": [
                    {
                        "text": "What is Data Integration?",
                        "url": "https://www.talend.com/resources/what-is-data-integration/"
                    },
                    {
                        "text": "Data Integration Best Practices",
                        "url": "https://hevodata.com/learn/data-integration-best-practices/"
                    }
                ]
            },
            {
                "title": "üß∞ Data Quality",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            },
            {
                "title": "‚öñÔ∏è Data Management",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            },
            {
                "title": "üîë Data Security",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            }
        ]
    },
    {
        "title": "Data Analysis",
        "items": [
            {
                "title": "üî¨ Data Visualization",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            },
            {
                "title": "üìä Statistics",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            },
            {
                "title": "üß¨ Machine Learning",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            }
        ]
    },
    {
        "title": "Data Pipelines & Flows",
        "items": [
            {
                "title": "üå´Ô∏è Data Streaming",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            },
            {
                "title": "üåä Batch Processing",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            },
            {
                "title": "‚ö° Change Data Capture",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            },
            {
                "title": "üåå Data Manipulation",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            }
        ]
    },
    {
        "title": "Cloud Infrastructure",
        "items": [
            {
                "title": "‚òÅÔ∏è Cloud Computing",
                "shortdescription": "What is Cloud Computing?",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            },
            {
                "title": "‚õÖ AWS, Azure, GCP",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            },
            {
                "title": "üå®Ô∏è Others",
                "shortdescription": "Learn the basics about version control",
                "links": [
                    {
                        "text": "What is ?",
                        "url": ""
                    }
                ]
            }
        ]
    }
]
